seed: 3407
pretrained_model: google/flan-t5-base
tokenizer_name: google/flan-t5-base
device: cuda

datamodule:
  trainset_path: ../dataset/trainset_pro.parquet
  testset_path: ../dataset/testset_pro.parquet
  feature_col: text
  label_col: label
  max_length: 512
  batch_size: 8
  test_size: 0.2
  stratify_col: label

model:
  hidden_size: 512
  layer_sizes: []
  unfreeze_layers: [-1]
  num_labels: 3
  dropout: 0.15
  activation: LeakyReLU

trainer:
  num_epochs: 2
  lr: 8e-05
  weight_decay: 0.01
  warm_up_step: 0.1
  early_stop: True
