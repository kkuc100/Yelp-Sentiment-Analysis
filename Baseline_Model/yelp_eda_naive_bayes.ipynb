{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTW9bApUattE"
      },
      "source": [
        "# Yelp Sentiment CSV\n",
        "266 Summer 2024\n",
        "Kevin Kuc, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKiliRegbDzj"
      },
      "source": [
        "The data is publically available here:\n",
        "*   https://huggingface.co/datasets/Yelp/yelp_review_full\n",
        "\n",
        "\n",
        "**Data Dictionary**\n",
        "\n",
        "1.   'text': The review texts are escaped using double quotes (\"), and any internal double quote is escaped by 2 double quotes (\"\"). New lines are escaped by a backslash followed with an \"n\" character, that is \"\\n\".\n",
        "2.   'label': Corresponds to the score associated with the review (between 1 and 5)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxG_clgliD3S"
      },
      "source": [
        "## Step 1: Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4HU-TTTLiUab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kevinkuc/Documents/Yelp-Sentiment-Analysis/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import copy\n",
        "from datasets import load_dataset\n",
        "\n",
        "# data preprocessing\n",
        "from sklearn import preprocessing\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from numpy.random.mtrand import binomial\n",
        "import random\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from contractions import fix\n",
        "\n",
        "# exploratory analysis\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
        "import mlxtend\n",
        "from mlxtend.plotting import scatterplotmatrix\n",
        "from mlxtend.plotting import heatmap\n",
        "import seaborn as sns\n",
        "from IPython.display import Image\n",
        "from textblob import TextBlob\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# model fit\n",
        "import statsmodels.api as sm\n",
        "#import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "#from keras import metrics\n",
        "#from tensorflow.keras import initializers\n",
        "\n",
        "\n",
        "# ignore warnings (libraries are rapidly changing)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
        "\n",
        "# These commands below set some options for pandas and to have matplotlib show the charts in the notebook\n",
        "pd.set_option('display.max_rows', 1000)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "pd.options.mode.chained_assignment = None  # default='warn'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHv2i3W5ijto"
      },
      "source": [
        "## Step 2: Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XkCqoc1kMnU",
        "outputId": "50c2a0f8-b7ec-4a86-e93e-e556714d50b4"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset('yelp_review_full')\n",
        "df_train = dataset['train'].to_pandas()\n",
        "df_test = dataset['test'].to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 3.1: Preprocess Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_review(review):\n",
        "    \"\"\"Ensures the input is a string, converts it to lovercase, removes puncuation, \n",
        "    keeps alphabetical words only, remove any whitespaces\"\"\"\n",
        "    if isinstance(review, list):\n",
        "        review = ' '.join(review)\n",
        "    review = review.lower()\n",
        "    review = ''.join([char for char in review if char not in string.punctuation])\n",
        "    review = ' '.join([word for word in review.split() if word.isalpha()])\n",
        "    review = ' '.join(review.split())\n",
        "    return review\n",
        "\n",
        "df_train['text'] = df_train['text'].apply(preprocess_review)\n",
        "df_test['text'] = df_test['text'].apply(preprocess_review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 3.1.1: Adjust text length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#sampled_df['text_length'] = sampled_df['text'].apply(len)\n",
        "\n",
        "# Calculate the average text length\n",
        "#average_length = sampled_df['text_length'].mean()\n",
        "#sampled_df = sampled_df[(sampled_df['text_length'] > (average_length-300)) & (sampled_df['text_length'] < (average_length+300))]\n",
        "#sampled_df[\"label\"].value_counts().sort_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 3.5: Export Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export to csv\n",
        "df_train.to_csv('train_allstars.csv', index=False)\n",
        "df_test.to_csv('test_allstars.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
